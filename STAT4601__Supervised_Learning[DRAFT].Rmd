---
title: "STAT4601_FINAL_PROJECT"
author: "Trae Smith"
date: "2025-04-03"
output: 
  pdf_document: 
    toc: true
---

```{r setup, include=FALSE}
source("get.train.R")
source("myknn.R")
source("f.create.grid.R")
source("draw.circle.R")

library(asbio)
library(DescTools)
library(tidyverse)
library(fastICA)
library(class)
library(caret)
library(pROC)
library(rpart)
library(rpart.plot)
library(nnet)
library(knitr)
library(NeuralNetTools)
```




```{r define_w/o, results='hide', echo=TRUE}
## Frist, we will need to define this model for K Nearest Neighbors
"%w/o%" <- function(x, y) x[!x %in% y]


```



```{r KNN_model}

set.seed(1234)

##I will be splitting the updated_nyc_data into a training data (80%) and a testing data (20%) to train the models below. ##I will also be setting the Borough as a factor to ensure that it is treated as a categorical variable
splitter<-get.train(nrow(updated_nyc_data), train.sz = round(0.8 * nrow(updated_nyc_data)))
updated_nyc_data$BOROUGH <- as.factor(updated_nyc_data$BOROUGH)


train_data <- updated_nyc_data[splitter$train, ] 
test_data <- updated_nyc_data[splitter$test, ]   

train_data$BOROUGH <-as.factor(train_data$BOROUGH)
test_data$BOROUGH <- as.factor(test_data$BOROUGH)

#This is for the test data for New York (across the 5 Boroughs). Since there is 5 Boroughs, we can use the number of nearest neighbors as 5 to classify the data. 
knn_model <- knn(train_data, test_data, train_data$BOROUGH, k = 5, prob=TRUE)
summary(knn_model)

#Using the ICA, we found out that the most indepedent components are the 2nd and 5th component, which is both contributed by sale price (and second for 2nd component is land (square feet) and for 5th component is gross sqaure feet). Due to the large size of sale price, we will instead use land (square feet) and gross square feet as our example visualization of the data.

nyc_subset <- updated_nyc_data[, c(11,12,1)]
nyc_subset$BOROUGH <- as.numeric(nyc_subset$BOROUGH)
nyc_mat<-as.matrix(nyc_subset)
nyc_grid<-f.create.grid(nyc_mat, c(10,10))

##Using myknn to visualize the data using the 8th and 9th category
myknn(k=5, nyc_mat, nyc_grid)


```
Looking at the summary, we can see that 284 went to the 1st nearest neighbor, 798 went to the 2nd nearest neighbor, 2799 went to the 3rd nearest neighbor, 2991 went to the 4th nearest neighbor, and 1096 went to the 5th nearest neighbor. This, along with the actual size for each one, shows that the 5th neighbor have a bit more biased compared to the other neighbors, while the 1st neighbor have less bias compared to the other neighbors. This is contradictory, as the 1st neighbor should instead have more bias compared to 5th neighbor. 


The chart also shows a significant amount of overlap between the different boroughs towards the beginning, so the lines differentiating them are struggling for a bit. This is due to the fact that the different boroughs are close to each other, and as such, the KNN model is struggling to classify them. This is where the different biases come, as the 5th neighbor is more biased towards the other boroughs, while the 1st neighbor is less biased towards the other boroughs.


```{r Confusion_Matrix_and_Model_analysis_for_KNN}

#Confusion Matrix
knn_confusion<-confusionMatrix(knn_model, test_data$BOROUGH)
metrics <- data.frame(
  Class = rownames(knn_confusion$byClass),
  Precision = knn_confusion$byClass[, "Pos Pred Value"],
  Recall = knn_confusion$byClass[, "Sensitivity"],
  F1 = knn_confusion$byClass[, "F1"],
  Balanced_Accuracy = knn_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = knn_confusion$byClass[, "Specificity"]
)
print(metrics)

prob<-attr(knn_model, "prob")

probs <- list(ifelse(knn_model == 1, prob, 1 - prob), ifelse(knn_model == 2, prob, 1 - prob), ifelse(knn_model == 3, prob, 1 - prob), ifelse(knn_model == 4, prob, 1 - prob),ifelse(knn_model == 5, prob, 1 - prob))


#To Visualize the ROC for the different Boroughs, along with their AUC values, 
boroughs <- levels(test_data$BOROUGH)
colors <- rainbow(length(boroughs))


plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "KNN ROC Curves for Each Borough")

auc_values <- c()

# Loop through boroughs
for (i in seq_along(as.numeric(boroughs))) {
  b <- as.numeric(boroughs[i])
  test_data_bin <- ifelse(as.numeric(test_data$BOROUGH) == b, 1, 0)
  probs_bin <- probs[[b]]
  
  roc_knn <- roc(test_data_bin, probs_bin)
  auc_val <- auc(roc_knn)
  auc_values <- c(auc_values, auc_val)
  
  lines(roc_knn, col = colors[i], lwd = 2)
}

# Add legend with AUC
legend("bottomright",
       legend = paste0(boroughs, " (AUC = ", round(auc_values, 3), ")"),
       col = colors, lwd = 2)






```

The Precision, recall, and (as such) F1 score aren't as high, due to the false placements of classes that occurred. The balanced accuracy and specificity is higher as there is a lot of observations, so they'll take that into consideration as well. 


We can also see this being applied to the ROC and AUC values, as they're not as low as their precision, recall, and F1 score. 


```{r Classification_Tree_(CART)}

##Training the model for classification trees
cart_model <- rpart(BOROUGH ~ ., data = train_data, method = "class", control = rpart.control(cp=0.001, maxdepth = 4, minsplit = 10))
cart_model$variable.importance
#Tree Visualization
rpart.plot(cart_model)
##We can see that Zip code is extrememly important when it comes to classifying the different boroughs, which makes sense as the different boroughs are in different areas, which is in different zip codes. However, with the classification, it appears that it struggles to classify the differet boroughs appropriately. As such, I have decided to remove zip code for this model. 
temp_data<-train_data[,-c(7)]
#To ensure all boroughs are used, we will set maxdepth as 5, while complexity parameter is 0.01 and minimum number of observations is 10 . 
updated_cart_model<- rpart(BOROUGH ~ ., data = temp_data, method = "class", control = rpart.control(cp=0.001, maxdepth = 5, minsplit=10))


```
Not only does the classification tree show relies too much on zip code, it causes a major amount of issues when it comes to actually classifying the different boroughs. As such, I have decided to remove zip code to this model. 
```{r Updated_Tree_Visualization, fig.align='center',fig.width=20, fig.height=10}}

#Tree Visualization
rpart.plot(updated_cart_model, 
           extra = 106, 
           faclen = 0,
           compress=FALSE,
           tweak=1.5,
           fallen.leaves = TRUE)

```
This provides a more comprehensive classification, utilizing blocks, year built, lot, building class at present and at time of sale, and land (square feet) to classify the different boroughs. 

```{r Confusion_Matrix_and_Model_analysis_for_CART}


#Predicting the test data
cart_pred <- predict(updated_cart_model, test_data, type = "class")

#Confusion Matrix
cart_confusion <- confusionMatrix(cart_pred, test_data$BOROUGH)
cart_metrics <- data.frame(
  Class = rownames(cart_confusion$byClass),
  Precision = cart_confusion$byClass[, "Pos Pred Value"],
  Recall = cart_confusion$byClass[, "Sensitivity"],
  F1 = cart_confusion$byClass[, "F1"],
  Balanced_Accuracy = cart_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = cart_confusion$byClass[, "Specificity"]
)
print(cart_metrics)



cart_probs <- predict(updated_cart_model, test_data, type = "prob")
cart_probs_list <- list()

for (b in as.numeric(boroughs)) {
  cart_probs_list[[b]] <- cart_probs[, b]
}



#We will utilize the same colors as before for BOROUGHS

graphics.off()
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "CART ROC Curves for Each Borough")

auc_cart <- c()

# Loop through boroughs
for (i in seq_along(as.numeric(boroughs))) {
  b <- as.numeric(boroughs[i])
  test_data_bin <- ifelse(as.numeric(test_data$BOROUGH) == b, 1, 0)
  probs_bin <- cart_probs_list[[b]]
  
  roc_cart <- roc(test_data_bin, probs_bin)
  auc_car <- auc(roc_cart)
  auc_cart <- c(auc_cart, auc_car)
  
  lines(roc_cart, col = colors[i], lwd = 2)
}

#legend with AUC
legend("bottomright",
       legend = paste0(boroughs, " (AUC = ", round(auc_cart, 3), ")"),
       col = colors, lwd = 1)

```
Looking at this, they're quite a bit of differences in the precision, recall, F1, balanced accuracy, and specificity. Brorough 2 struggled a bit throughout these calculations compared to the other boroughs. 

However, Borough 2 have a pretty high AUC value and ROC curve, along with the other boroughs. This shows that, despite the low calculations for borough 2, it is still a good model to use. 

```{r Neural_Networks}

##Before we train the neural networks model, we first have to normalize the data
normalize <- function(x) (x - min(x)) / (max(x) - min(x))

train_x <- as.data.frame(lapply(train_data[, sapply(train_data, is.numeric)], normalize))
test_x <- as.data.frame(lapply(test_data[, sapply(test_data, is.numeric)], normalize))

# Recombine with labels
train_nn <- data.frame(BOROUGH = train_data$BOROUGH, train_x)
test_nn <- data.frame(BOROUGH = test_data$BOROUGH, test_x)

##Training the neural networks model, size is 5 due to the amount of boroughs, the maximum iterations is 2500 as it can go up to that amount of iterations before it converges. However, there was overfitting, so i decided to add in decay and reduce the size to 2.
set.seed(1234) #To ensure consistency

nn_model <- nnet(BOROUGH ~. , data = train_nn, size = 2, maxit = 600, trace = FALSE, decay=0.5)
summary(nn_model)

```
This Neural Networks model contains 47 weights and is a 15, 2, 5 model. I6 (which is the zip code) have the most weight when it goes into the 1st hidden layer, though not as much. the 2nd hidden layer is dominated by I5 (which is building class at present) significantly.

The 1st hidden layer dominates output 1, 4, and 5, while the 2nd hidden layer didnt really dominate any output. 



```{r Confusion_Matrix_and Model_analysis_for_Neural_Networks}

# Predicted classes
nn_pred <- predict(nn_model, test_nn, type = "class")
#change as a factor
nn_conf<-factor(nn_pred, levels = levels(test_nn$BOROUGH))

# Confusion matrix + accuracy + F1 + recall + precision
nn_confusion <- confusionMatrix(nn_conf, test_nn$BOROUGH)
nn_metrics <- data.frame(
  Class = rownames(nn_confusion$byClass),
  Precision = nn_confusion$byClass[, "Pos Pred Value"],
  Recall = nn_confusion$byClass[, "Sensitivity"],
  F1 = nn_confusion$byClass[, "F1"],
  Balanced_Accuracy = nn_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = nn_confusion$byClass[, "Specificity"]
)
print(nn_metrics)


nn_probs <- predict(nn_model, test_nn, type = "raw")
nn_probs_list <- list()
for (b in as.numeric(boroughs)) {
  nn_probs_list[[b]] <- nn_probs[, b]
}


#plotting for Neural Networks (ROC and AUC)
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "Neural Network ROC Curves for Each Borough")

auc_nn <- c()

for (i in seq_along(boroughs)) {
  b <- as.numeric(boroughs[i])
  test_nn_bin <- ifelse(as.numeric(test_nn$BOROUGH) == b, 1, 0)
  probs_bin <- nn_probs_list[[b]]
  
  roc_nn <- roc(response = test_nn_bin, predictor = probs_bin)
  auc_neunet <- auc(roc_nn)
  auc_nn <- c(auc_nn, auc_neunet)
  
  lines(roc_nn, col = colors[i], lwd = 2)
}

legend("bottomright",
       legend = paste0(boroughs, " (AUC = ", round(auc_nn, 3), ")"),
       col = colors, lwd = 2)

```
Looking at this too, we can tell that Neural Networks are also pretty efficient, having a high precision, recall, f1, balanced accuracy, and specificity. 

This is especially reflective in the ROC curve and AUC values, as all of them are close to perfect.

```{r Logistics_Regression}

##Since Logistics regression is a binary classification, we will use a multinomial regression to classify the data
#The max iterations is 750 to ensure that it converges
logistic_model <- multinom(BOROUGH ~ ., data = train_data, maxit=750, trace=FALSE)
summary(logistic_model)

```
This model on the other hand provides a formula which can be used to classify the data. If the value falls within the area of the formula for Borough x, then they will belong to said brorough. If it fails to meet any of the 4 above, then it will be classified to the default, Borough 1. We can see that zip code, land (square feet), and block are the factors that dominate this model as well.  

```{r Confusion_Matrix_and_Model_analysis_for_Logistics_Regression}

logistic_pred <- predict(logistic_model, test_data)
logistic_conf <- factor(logistic_pred, levels = levels(test_data$BOROUGH))
# Confusion matrix + accuracy + F1 + recall + precision
logistic_confusion <- confusionMatrix(logistic_conf, test_data$BOROUGH)
logistic_metrics <- data.frame(
  Class = rownames(logistic_confusion$byClass),
  Precision = logistic_confusion$byClass[, "Pos Pred Value"],
  Recall = logistic_confusion$byClass[, "Sensitivity"],
  F1 = logistic_confusion$byClass[, "F1"],
  Balanced_Accuracy = logistic_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = logistic_confusion$byClass[, "Specificity"]
)
print(logistic_metrics)
logistic_probs <- predict(logistic_model, test_data, type = "prob")
logistic_probs_list <- list()

for (b in as.numeric(boroughs)) {
  logistic_probs_list[[b]] <- logistic_probs[, b]
}

#plotting for Logistics Regression (ROC and AUC)
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "Multinomial Logistic ROC Curves for Each Borough")

auc_logit <- c()

for (i in seq_along(boroughs)) {
  b <- as.numeric(boroughs[i])
  test_logit_bin <- ifelse(as.numeric(test_data$BOROUGH) == b, 1, 0)
  probs_bin <- logistic_probs_list[[b]]
  
  roc_logit <- roc(response = test_logit_bin, predictor = probs_bin)
  auc_logistics <- auc(roc_logit)
  auc_logit <- c(auc_logit, auc_logistics)
  
  lines(roc_logit, col = colors[i], lwd = 2)
}

legend("bottomright",
       legend = paste0(boroughs, " (AUC = ", round(auc_logit, 3), ")"),
       col = colors, lwd = 2)
```

With the Multinomial Logistics regression, we can see that precision, recall, f1, balanced accuracy, and specificity are all high.

This is also reflected in the ROC and AUC values, where they are all close to perfect, if not perfect (which is the case for borough 2 and 5)



```{r AUC_Comparison_and_Final_Analysis}

# AUC values from your models
auc_comparison <- data.frame(
  Model = c("KNN", "CART", "Neural Net", "Multinomial LR"),
  Borough1 = c(0.881, 0.909, 0.997, 0.999),
  Borough2 = c(0.903, 0.873, 0.999, 1),
  Borough3 = c(0.897, 0.868, 0.966, 0.966),
  Borough4 = c(0.905, 0.851, 0.969, 0.969),
  Borough5 = c(0.929, 0.907, 0.991, 1)
)

auc_comparison
```

Amongst all of these data sets, we can see that the Neural Networks model as well as the Multinomial Logistics Regression model are the most efficient when it comes to the classification of the different boroughs. Since they have close to perfect precision, recall, F1, balanced accuracy, and specificity, as well as having a near perfect ROC curve and AUC value, these two would be the best models to use for future data sets relating to classifying the different boroughs based on the different features. The Classification Tree model and the K-Nearest Neighbors is a suitable alternative, as it also have a high amount of precision, recall, F1, balanced accuracy, and specificity, as well as a high ROC curve and AUC value. If Neural Networks and Logistics Regression are not available, then these would be the next best model to use.  







