---
title: "STAT4601_FINAL_PROJECT"
author: "Trae Smith"
date: "2025-04-03"
output: 
  pdf_document: 
    toc: true
---

```{r setup, include=FALSE}
source("get.train.R")
source("myknn.R")
source("f.create.grid.R")
source("draw.circle.R")

library(asbio)
library(DescTools)
library(tidyverse)
library(fastICA)
library(class)
library(caret)
library(pROC)
library(rpart)
library(rpart.plot)
library(nnet)
library(knitr)
library(NeuralNetTools)
```

```{r PCA, echo=FALSE}
##PCA for the dataset, specifically for the numericals, along with the standardization
#New_York_City
pca_new_york_city<-prcomp(new_york_city_data, scale.=TRUE)
summary(pca_new_york_city)
apply(pca_new_york_city$rotation, 2, function(x) names(sort(abs(x), decreasing = TRUE)[1]))

#Since Borough is a constant value for each individual borough, we will have to remove it for Principal Component Analysis
#Brooklyn
pca_brooklyn<-prcomp(brooklyn_data[,-c(1)], scale.=TRUE)
summary(pca_brooklyn)
apply(pca_brooklyn$rotation, 2, function(x) names(sort(abs(x), decreasing = TRUE)[1]))

#Manhattan
pca_manhattan<-prcomp(manhattan_data[,-c(1)], scale.=TRUE)
summary(pca_manhattan)
apply(pca_manhattan$rotation, 2, function(x) names(sort(abs(x), decreasing = TRUE)[1]))

#Bronx
pca_bronx<-prcomp(bronx_data[,-c(1)], scale.=TRUE)
summary(pca_bronx)
apply(pca_bronx$rotation, 2, function(x) names(sort(abs(x), decreasing = TRUE)[1]))

#Queens
pca_queens<-prcomp(queens_data[,-c(1)], scale.=TRUE)
summary(pca_queens)
apply(pca_queens$rotation, 2, function(x) names(sort(abs(x), decreasing = TRUE)[1]))

#Staten Island
pca_staten_island<-prcomp(staten_island_data[,-c(1)], scale.=TRUE)
summary(pca_staten_island)
apply(pca_staten_island$rotation, 2, function(x) names(sort(abs(x), decreasing = TRUE)[1]))





```
Looking at this, to achieve 90 percent of the variance, we need 8  principal components for the overall (new york city) data, 7 principal components for Brooklyn, Queens, and Staten Island, and 6 principal components for Manhattan and Bronx. 

The variables that contributed the most to each principal component required to achieve at least 90% variance (in order) for new york city is tax class at time of sale, residential units, year built, commercial units, land (square feet), commercial units, land (square feet), and sale price. 

For Brooklyn, the variables are building class category, residential units, sale price, commercial units, zip code, year built, and commercial units

For Manhattan, the variables are gross square feet, residential units, sale price (for both PC3 and PC4), commercial units, and land (square feet)

For Bronx, the variables are building class category, residential units, land (square feet), zip code, building class at present, and year built

For Queens, the variables are building class category, residential units, zip code, year built, zip code, commercial units, and land (square feet)

Finally, for Staten Island, the variables are building class category, residential units, land (square feet), year built, zip code, land (square feet), and commercial units.





```{r ICA, echo=FALSE}
set.seed(1234)
#we can also use ICA to find the independent components of the dataset
ICA_nyc<-fastICA(new_york_city_data, n.comp =8)
ICA_brooklyn<-fastICA(brooklyn_data, n.comp =7)
ICA_manhattan<-fastICA(manhattan_data, n.comp =6)
ICA_bronx<-fastICA(bronx_data, n.comp =6)
ICA_queens<-fastICA(queens_data, n.comp =7)
ICA_staten_island<-fastICA(staten_island_data, n.comp =7)





```
Since all of the correlation of prinicipal components are close to 0, we can say that they are independent. 



```{r Save_Datasets, echo=FALSE}

save(manhattan_data, file = "manhattan_data.RData")
save(bronx_data, file = "bronx_data.RData")
save(brooklyn_data, file = "brooklyn_data.RData")
save(queens_data, file = "queens_data.RData")
save(staten_island_data, file = "staten_island_data.RData")
save(new_york_city_data, file = "new_york_city_data.RData")

##PCA Data
save(pca_new_york_city, file = "pca_new_york_city.RData")
save(pca_brooklyn, file = "pca_brooklyn.RData")
save(pca_manhattan, file = "pca_manhattan.RData")
save(pca_bronx, file = "pca_bronx.RData")
save(pca_queens, file = "pca_queens.RData")
save(pca_staten_island, file = "pca_staten_island.RData")


#ICA Data
save(ICA_nyc, file = "ICA_nyc.RData")
save(ICA_brooklyn, file = "ICA_brooklyn.RData")
save(ICA_manhattan, file = "ICA_manhattan.RData")
save(ICA_bronx, file = "ICA_bronx.RData")
save(ICA_queens, file = "ICA_queens.RData")
save(ICA_staten_island, file = "ICA_staten_island.RData")

```

```{r Linear_Regression, echo=FALSE}
#Vs Gross Square Feet
lr_model <- lm(SALE.PRICE ~ GROSS.SQUARE.FEET, data = new_york_city_data)
summary(lr_model)
```

```{r Analysis_overall_for_Linear_Regression, echo=FALSE}

predicted_prices <- predict(lr_model, newdata = new_york_city_data)

# Calculate Mean Squared Error (MSE)
mse <- mean((new_york_city_data$SALE.PRICE - predicted_prices)^2)

# Root Mean Squared Error (RMSE)
rmse <- sqrt(mse)


plot(new_york_city_data$GROSS.SQUARE.FEET, new_york_city_data$SALE.PRICE,
     main = "Linear Regression: Price vs. Size",
     xlab = "Gross Sq Ft", ylab = "Sale Price", pch = 20, col = "steelblue")
abline(lr_model, col = "red", lwd = 2)

```




```{r Individual_Borough_Analysis, echo=FALSE}

boroughs_list <- list(
  Manhattan = manhattan_data,
  Brooklyn = brooklyn_data,
  Queens = queens_data,
  Bronx = bronx_data,
  StatenIsland = staten_island_data
)

for (name in names(boroughs_list)) {
  cat("===== Borough:", name, "=====\n")
  
  borough_data <- boroughs_list[[name]]
  borough_data <- borough_data[borough_data$SALE.PRICE > 0 & borough_data$GROSS.SQUARE.FEET > 0, ]
  borough_data <- na.omit(borough_data)
  
  if (nrow(borough_data) < 10) next  # skip small datasets

  lm_model <- lm(SALE.PRICE ~ GROSS.SQUARE.FEET, data = borough_data)
  pred <- predict(lm_model, newdata = borough_data)

  mse <- mean((borough_data$SALE.PRICE - pred)^2)
  rmse <- sqrt(mse)
  r2 <- summary(lm_model)$r.squared
  
  cat("RMSE:", round(rmse, 2), "\n")
  cat("RÂ²:", round(r2, 4), "\n\n")
  
  
  plot(borough_data$GROSS.SQUARE.FEET, borough_data$SALE.PRICE,
       main = paste("Linear Regression -", name),
       xlab = "Gross Sq Ft", ylab = "Sale Price", pch = 20, col = "steelblue")

  abline(lm_model, col = "red", lwd = 2)

}




```
The scatterplots show that the majority of properties cluster tightly in a lower range of square footage and sale price, with a few extreme outliers (often luxury properties) stretching the scale. This compresses the main data area and visually hides much of the structure. It also suggests that linear regression may struggle to model the full range of sale prices effectively.


For the individual Boroughs, you can tell that Staten Island have the highest sale price per gross square feet


```{r define_w/o, results='hide', echo=TRUE}
## First, we will need to define this model for K Nearest Neighbors
"%w/o%" <- function(x, y) x[!x %in% y]


```



```{r KNN_model, echo=FALSE}

set.seed(1234)


#To ensure that we classify the data by sale price, we will categorize the sale price from 0 to 5.6*10^8 by Very Low, Low, Medium, and High. Since there is $0 for some of the sale prices, due to transfers and other reasons, they are not considered sales. Since they are not considered sales, they could skew the data when it comes to predicting the different class prices, and as such would be removed from this analysis. 

new_york_city_data$PRICE.CAT <-cut(
    new_york_city_data$SALE.PRICE,
    breaks = quantile(new_york_city_data$SALE.PRICE, probs = c(0,1/3,2/3,1), na.rm = TRUE),
    include.lowest = TRUE,
    labels = c("Low", "Medium", "High"))

##To compare the model across boroughs, i will use the cutoff values for new york city to as the cutoffs for the individual boroughs. 


cutoff <- quantile(new_york_city_data$SALE.PRICE, probs = c(0,1/3,2/3,1), na.rm = TRUE)


for (name in names(boroughs_list)) {
  boroughs_list[[name]]$PRICE.CAT <- cut(
    boroughs_list[[name]]$SALE.PRICE,
    breaks = cutoff,
    include.lowest = TRUE,
    labels = c("Low", "Medium", "High")
  )
}




##I will be splitting the new_york_city_data into a training data (80%) and a testing data (20%) to train the models below according to the proportions. 
splitter  <- createDataPartition(new_york_city_data$PRICE.CAT, p = 0.8, list = FALSE)


#Since KNN requires the data to be numeric, we will convert the categorical variables to numeric
new_york_city_data$PRICE.CAT <- as.numeric(new_york_city_data$PRICE.CAT)


train_data <- new_york_city_data[splitter,] 
test_data <- new_york_city_data[-splitter,]   

#Since Sale Price is the target variable, we will remove it from the training and testing data 
train_data <- train_data[,-c(14)]
test_data <- test_data[,-c(14)]


#This is for the test data for New York (across the 3 price categories). Since there is 3 price categories, we can use the number of nearest neighbors as 3 to classify the data. 
knn_model_nyc <- knn(train_data, test_data, train_data$PRICE.CAT, k = 3, prob = TRUE)
summary(knn_model_nyc)

#Using the ICA, we found out that the most indepedent components are the 2nd and 5th component, which is both dominated by sale price (our target variable),  gross square feet, and block, so we will use them to visualize it using myknn

nyc_subset <- new_york_city_data[, c(9,10,15)]
nyc_subset$PRICE.CAT <- as.numeric(nyc_subset$PRICE.CAT)
nyc_mat<-as.matrix(nyc_subset)
nyc_grid<-f.create.grid(nyc_mat, c(10,10))

##Using myknn to visualize the data using the 8th and 9th category
myknn(k=3, nyc_mat, nyc_grid)


#Reverting price categories as factors (1 is low, 2, is medium, 3 is high, 4 is very low)
train_data$PRICE.CAT <-as.factor(train_data$PRICE.CAT)
test_data$PRICE.CAT <- as.factor(test_data$PRICE.CAT)



```
Looking at the summary, we can see that 1450 went to the 1st nearest neighbor, 1462 went to the 2nd nearest neighbor, and 1695  went to the 3rd nearest neighbor. This shows that there is a slight bias towards the 3rd category (High), compared to the other 2 categories. 



```{r Confusion_Matrix_and_Model_analysis_for_KNN, echo=FALSE}


#Confusion Matrix
knn_confusion<-confusionMatrix(knn_model_nyc, factor(test_data$PRICE.CAT))
metrics <- data.frame(
  Class = rownames(knn_confusion$byClass),
  Precision = knn_confusion$byClass[, "Pos Pred Value"],
  Recall = knn_confusion$byClass[, "Sensitivity"],
  F1 = knn_confusion$byClass[, "F1"],
  Balanced_Accuracy = knn_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = knn_confusion$byClass[, "Specificity"]
)
print(metrics)

prob<-attr(knn_model_nyc, "prob")

probs <- list(
  ifelse(knn_model_nyc == 1, prob, 1 - prob), 
              ifelse(knn_model_nyc == 2, prob, 1 - prob), 
              ifelse(knn_model_nyc == 3, prob, 1 - prob)
  )


#To Visualize the ROC for the different Boroughs, along with their AUC values, 
categories <- levels(factor(test_data$PRICE.CAT))
colors <- rainbow(length(categories))


plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "KNN ROC Curves for Each Price Categories")

auc_values <- c()

# Loop through categories
for (i in seq_along(as.numeric(categories))) {
  b <- as.numeric(categories[i])
  test_data_bin <- ifelse(as.numeric(test_data$PRICE.CAT) == b, 1, 0)
  probs_bin <- probs[[b]]
  
  roc_knn <- roc(test_data_bin, probs_bin)
  auc_val <- auc(roc_knn)
  auc_values <- c(auc_values, auc_val)
  
  lines(roc_knn, col = colors[i], lwd = 2)
}

# Add legend with AUC
legend("bottomright",
       legend = paste0(categories, " (AUC = ", round(auc_values, 3), ")"),
       col = colors, lwd = 2)


```

Other from Specificity, the KNN model doesn't have large percentages. Category 3 (high) is the most accurate among the 3, while category 2 is the least. 


We can also see this being applied to the ROC and AUC values, with category 3 having the highest AUC value, then after is category 1 and finally category 2. 


```{r Boroughs Predictions for KNN, echo=FALSE}
# Set up a color palette for the categories

# Optional: Save plots as images
# dir.create("plots")

i <- 0
for (name in names(boroughs_list)) {
  borough_data <- boroughs_list[[name]]
  borough_data$PRICE.CAT <- as.numeric(borough_data$PRICE.CAT)
  borough.predictors <- borough_data[-c(14)]
  i <- i + 1
  
  # Predict
  preds <- knn(train = train_data,
               test = borough.predictors,
               cl = train_data$PRICE.CAT,
               k = 3, 
               prob = TRUE)
  
  # Confusion matrix
  knn_confusion <- confusionMatrix(factor(preds), factor(borough_data$PRICE.CAT))
  
  cat(name,"\n")
  print(knn_confusion$overall["Accuracy"])
  print(knn_confusion$byClass[, c("Sensitivity", "Precision", "Recall", 
                                  "Balanced Accuracy", "F1", "Specificity")])
  
  # Extract probabilities for each class
  prob <- attr(preds, "prob")
  knn_probs <- list(
    ifelse(preds == 1, prob, 1 - prob),
    ifelse(preds == 2, prob, 1 - prob),
    ifelse(preds == 3, prob, 1 - prob)
  )
  
 

  plot(NA, xlim = c(0, 1), ylim = c(0, 1),
       xlab = "False Positive Rate", ylab = "True Positive Rate",
       main = paste("K-Nearest Neighbors ROC for", name))
  
  auc_knn <- c()
  
  for (j in seq_along(categories)) {
    b <- as.numeric(categories[j])
    test_knn_bin <- ifelse(borough.predictors$PRICE.CAT == b, 1, 0)
    probs_bin <- knn_probs[[b]]
    roc_knn <- roc(response = test_knn_bin, predictor = probs_bin)
    auc_val <- auc(roc_knn)
    auc_knn <- c(auc_knn, auc_val)
    
    lines(roc_knn, col = colors[j], lwd = 2)
  }
  
  legend("bottomright",
         legend = paste0("Category ", categories, " (AUC = ", round(auc_knn, 3), ")"),
         col = colors, lwd = 2)
  
  # dev.off()  # uncomment if saving plots to files
}





```

Seeing this, the individual boroughs had moderate accuracy, for each category. This is reinforced with the ROC and AUC curves. 












```{r Classification_Tree_(CART), echo=FALSE}

##Training the model for classification trees
cart_model <- rpart(PRICE.CAT ~ ., data = train_data, method = "class", control = rpart.control(cp=0.001, maxdepth = 4, minsplit = 10))
#To ensure all categories are used, we will set maxdepth as 5, while complexity parameter is 0.01 and minimum number of observations is 10 . 
updated_cart_model<- rpart(PRICE.CAT ~ ., data = train_data, method = "class", control = rpart.control(cp=0.001, maxdepth = 5, minsplit=10))


```
Not only does the classification tree show relies too much on zip code, it causes a major amount of issues when it comes to actually classifying the different boroughs. As such, I have decided to remove zip code to this model. 
```{r Updated_Tree_Visualization, fig.align='center',fig.width=20, fig.height=10}

#Tree Visualization
rpart.plot(updated_cart_model, 
           extra = 106, 
           faclen = 0,
           compress=FALSE,
           tweak=1.5,
           fallen.leaves = TRUE)

```
This provides a more comprehensive classification, utilizing zip code, year built, gross square feet, and borough (for overall), to decide which category the property belongs to in terms of sale price. 
```{r Confusion_Matrix_and_Model_analysis_for_CART, echo=FALSE}


#Predicting the test data
cart_pred <- predict(updated_cart_model, test_data, type = "class")

#Confusion Matrix
cart_confusion <- confusionMatrix(cart_pred, test_data$PRICE.CAT)
cart_metrics <- data.frame(
  Class = rownames(cart_confusion$byClass),
  Precision = cart_confusion$byClass[, "Pos Pred Value"],
  Recall = cart_confusion$byClass[, "Sensitivity"],
  F1 = cart_confusion$byClass[, "F1"],
  Balanced_Accuracy = cart_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = cart_confusion$byClass[, "Specificity"]
)
print(cart_metrics)



cart_probs <- predict(updated_cart_model, test_data, type = "prob")
cart_probs_list <- list()

for (b in as.numeric(categories)) {
  cart_probs_list[[b]] <- cart_probs[, b]
}



#We will utilize the same colors as before for categories

graphics.off()
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "CART ROC Curves for Each Price Categories")

auc_cart <- c()

# Loop through boroughs
for (i in seq_along(as.numeric(categories))) {
  b <- as.numeric(categories[i])
  test_data_bin <- ifelse(as.numeric(test_data$PRICE.CAT) == b, 1, 0)
  probs_bin <- cart_probs_list[[b]]
  
  roc_cart <- roc(test_data_bin, probs_bin)
  auc_car <- auc(roc_cart)
  auc_cart <- c(auc_cart, auc_car)
  
  lines(roc_cart, col = colors[i], lwd = 2)
}

#legend with AUC
legend("bottomright",
       legend = paste0(categories, " (AUC = ", round(auc_cart, 3), ")"),
       col = colors, lwd = 1)

```
Looking at this, it wasn't as accurate, especially for the 2nd category (medium), which is the least accurate. This is also shown in the ROC chart and AUC values, showing that the 2nd category was not predicted as accurate as the other 2 categories.  



```{r CART_Boroughs_Predictions, echo=FALSE}
print("CART analysis for each Borough")
i<-0
#Seeing how the model fits for each borough
for (name in names(boroughs_list)) {
  borough_data <- boroughs_list[[name]]
  borough_data$PRICE.CAT<-as.numeric(borough_data$PRICE.CAT)
  
  # Make sure predictors match training data
  borough.predictors <- borough_data
  i<-i+1
  # Predict
  preds <- predict(updated_cart_model, newdata = borough.predictors, type = "class")
  cart_confusion <- confusionMatrix(factor(preds), factor(borough_data$PRICE.CAT))
  
  #Printing the Result
  cat(name,"\n")
  print(cart_confusion$overall["Accuracy"])
  print(cart_confusion$byClass[, c("Sensitivity","Precision", "Recall","Balanced Accuracy", "F1", "Specificity")])
  cat("\n")
  
  cart_probs <- predict(updated_cart_model, newdata = borough.predictors, type = "prob")
  
  cart_probs_list <- list()
  for (b in as.numeric(categories)) {
    cart_probs_list[[b]] <- cart_probs[, b]
}


  plot(NA, xlim = c(0, 1), ylim = c(0, 1),
      xlab = "False Positive Rate", ylab = "True Positive Rate",
      main = paste("CART ROC Curves for", name))
  auc_cart <- c()

  for (j in seq_along(categories)) {
    b <- as.numeric(categories[j])
    test_cart_bin <- ifelse(as.numeric(borough.predictors$PRICE.CAT) == b, 1, 0)
    probs_bin <- cart_probs_list[[b]]
  
  roc_cart <- roc(response = test_cart_bin, predictor = probs_bin)
  auc_tree <- auc(roc_cart)
  auc_cart <- c(auc_cart, auc_tree)
  
  lines(roc_cart, col = colors[j], lwd = 2)
}

  legend("bottomright",
       legend = paste0(categories, " (AUC = ", round(auc_cart, 3), ")"),
       col = colors, lwd = 2)
}



```
Other from Manhattan, in which it essentially guessed, the CART model was able to predict some of the price categories of the individual boroughs. This could be that Manhattan could be an outlier when it comes to some sale prices, which caused a drop of accurate predictions. 
```{r Neural_Networks, echo=FALSE}

##Before we train the neural networks model, we first have to normalize the data
normalize <- function(x) (x - min(x)) / (max(x) - min(x))

train_x <- as.data.frame(lapply(train_data[, sapply(train_data, is.numeric)], normalize))
test_x <- as.data.frame(lapply(test_data[, sapply(test_data, is.numeric)], normalize))

# Recombine with labels
train_nn <- data.frame(PRICE.CAT = train_data$PRICE.CAT, train_x)
test_nn <- data.frame(PRICE.CAT = test_data$PRICE.CAT, test_x)


##Training the neural networks model, size is 5 due to the amount of boroughs, the maximum iterations is 2500 as it can go up to that amount of iterations before it converges. However, there was overfitting, so i decided to add in decay and reduce the size to 2.

set.seed(1234) #To ensure consistency
nn_model <- nnet(PRICE.CAT ~. , data = train_nn, size = 6, maxit = 1000, trace = FALSE, decay=0.01)


```
This Neural Networks model contains 97 weights and is a 14, 6 (hidden layers), 1 model.



```{r Confusion_Matrix_and Model_analysis_for_Neural_Networks, echo=FALSE}

# Predicted classes
nn_pred <- predict(nn_model, test_nn, type = "class")
#change as a factor
nn_conf<-factor(nn_pred, levels = levels(test_nn$PRICE.CAT))
# Confusion matrix + accuracy + F1 + recall + precision
nn_confusion <- confusionMatrix(nn_conf, test_nn$PRICE.CAT)
nn_metrics <- data.frame(
  Class = rownames(nn_confusion$byClass),
  Precision = nn_confusion$byClass[, "Pos Pred Value"],
  Recall = nn_confusion$byClass[, "Sensitivity"],
  F1 = nn_confusion$byClass[, "F1"],
  Balanced_Accuracy = nn_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = nn_confusion$byClass[, "Specificity"]
)
print(nn_metrics)


nn_probs <- predict(nn_model, test_nn, type = "raw")
nn_probs_list <- list()
for (b in as.numeric(categories)) {
  nn_probs_list[[b]] <- nn_probs[, b]
}


#plotting for Neural Networks (ROC and AUC)
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "Neural Network ROC Curves for Each Price Categories")

auc_nn <- c()

for (i in seq_along(categories)) {
  b <- as.numeric(categories[i])
  test_nn_bin <- ifelse(as.numeric(test_nn$PRICE.CAT) == b, 1, 0)
  probs_bin <- nn_probs_list[[b]]
  
  roc_nn <- roc(response = test_nn_bin, predictor = probs_bin)
  auc_neunet <- auc(roc_nn)
  auc_nn <- c(auc_nn, auc_neunet)
  
  lines(roc_nn, col = colors[i], lwd = 2)
}

legend("bottomright",
       legend = paste0(categories, " (AUC = ", round(auc_nn, 3), ")"),
       col = colors, lwd = 2)

```



```{r Borough analysis for Neural Networks, echo=FALSE}
#Seeing how the model fits for each borough
i<-0
for (name in names(boroughs_list)) {
  borough_data <- boroughs_list[[name]]
  borough_data$PRICE.CAT<-as.numeric(borough_data$PRICE.CAT)
  
  # Make sure predictors match training data
  borough.predictors <- borough_data
  i<-i+1
  # Predict
  preds <- predict(nn_model, newdata = borough.predictors, type = "class")
  
  nn_confusion <- confusionMatrix(factor(preds, levels=c(1,2,3)), factor(borough_data$PRICE.CAT), mode="everything") 
  
  
 
  ##Printing the Result
  cat(name,"\n")
  print(nn_confusion$overall["Accuracy"])
  print(nn_confusion$byClass[, c("Sensitivity","Precision", "Recall","Balanced Accuracy", "F1", "Specificity")])
  cat("\n")
  
  nn_probs <- predict(nn_model, newdata = borough.predictors, type = "raw")
  
  nn_probs_list <- list()
  for (b in as.numeric(categories)) {
    nn_probs_list[[b]] <- nn_probs[, b]
}


  plot(NA, xlim = c(0, 1), ylim = c(0, 1),
      xlab = "False Positive Rate", ylab = "True Positive Rate",
      main = paste("Neural Network ROC Curves for ", name))
  auc_nn <- c()

  for (j in seq_along(categories)) {
    b <- as.numeric(categories[j])
    test_nn_bin <- ifelse(as.numeric(borough.predictors$PRICE.CAT) == b, 1, 0)
    probs_bin <- nn_probs_list[[b]]
  
    roc_nn <- roc(response = test_nn_bin, predictor = probs_bin)
    auc_neunet <- auc(roc_nn)
    auc_nn <- c(auc_nn, auc_neunet)
  
    lines(roc_nn, col = colors[j], lwd = 2)
}

  legend("bottomright",
       legend = paste0(categories, " (AUC = ", round(auc_nn, 3), ")"),
       col = colors, lwd = 2)
}


```
While the overall data was able to predict fairly well, for each individual borough, the model struggled. It caused all of the points to be predicted into the 3rd category (high), which prevents it to perform well. 

```{r Logistics_Regression, echo=FALSE}

##Since Logistics regression is a binary classification, we will use a multinomial regression to classify the data
#The max iterations is 750 to ensure that it converges
logistic_model <- multinom(PRICE.CAT ~ ., data = train_data, maxit=750, trace=FALSE)

```
 

```{r Confusion_Matrix_and_Model_analysis_for_Logistics_Regression, echo=FALSE}

logistic_pred <- predict(logistic_model, test_data)
logistic_conf <- factor(logistic_pred, levels = levels(test_data$PRICE.CAT))
# Confusion matrix + accuracy + F1 + recall + precision
logistic_confusion <- confusionMatrix(logistic_conf, test_data$PRICE.CAT)
logistic_metrics <- data.frame(
  Class = rownames(logistic_confusion$byClass),
  Precision = logistic_confusion$byClass[, "Pos Pred Value"],
  Recall = logistic_confusion$byClass[, "Sensitivity"],
  F1 = logistic_confusion$byClass[, "F1"],
  Balanced_Accuracy = logistic_confusion$byClass[, "Balanced Accuracy"],  
  Specificity = logistic_confusion$byClass[, "Specificity"]
)
print(logistic_metrics)
logistic_probs <- predict(logistic_model, test_data, type = "prob")
logistic_probs_list <- list()

for (b in as.numeric(categories)) {
  logistic_probs_list[[b]] <- logistic_probs[, b]
}

#plotting for Logistics Regression (ROC and AUC)
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "Multinomial Logistic ROC Curves for Each Borough")

auc_logit <- c()

for (i in seq_along(categories)) {
  b <- as.numeric(categories[i])
  test_logit_bin <- ifelse(as.numeric(test_data$PRICE.CAT) == b, 1, 0)
  probs_bin <- logistic_probs_list[[b]]
  
  roc_logit <- roc(response = test_logit_bin, predictor = probs_bin)
  auc_logistics <- auc(roc_logit)
  auc_logit <- c(auc_logit, auc_logistics)
  
  lines(roc_logit, col = colors[i], lwd = 2)
}

legend("bottomright",
       legend = paste0(categories, " (AUC = ", round(auc_logit, 3), ")"),
       col = colors, lwd = 2)
```



```{r Borough_analysis_for_Logistics_Regression, echo=FALSE}
#Seeing how the model fits for each borough
i<-0
for (name in names(boroughs_list)) {
  borough_data <- boroughs_list[[name]]
  borough_data$PRICE.CAT<-as.numeric(borough_data$PRICE.CAT)
  i<-i+1
  # Ensure that the predictors match training data
  borough.predictors <- borough_data
  
  # Predict
  preds <- predict(logistic_model, newdata = borough.predictors, type = "class")
  borough_data$PRICE.CAT <- as.factor(borough_data$PRICE.CAT)
  logit_confusion <- confusionMatrix(factor(preds), factor(borough_data$PRICE.CAT), mode="everything")
  
  #Printing the result
  cat(name,"\n")
  print(logit_confusion$overall["Accuracy"])
  print(logit_confusion$byClass[, c("Sensitivity","Precision", "Recall","Balanced Accuracy", "F1", "Specificity")])
  cat("\n")

  logit_probs <- predict(logistic_model, newdata = borough.predictors, type = "prob")
  
  logit_probs_list <- list()
  for (b in as.numeric(categories)) {
    logit_probs_list[[b]] <- logit_probs[, b]
}


  plot(NA, xlim = c(0, 1), ylim = c(0, 1),
      xlab = "False Positive Rate", ylab = "True Positive Rate",
      main = paste("LR ROC Curves for ", name))
  auc_logit <- c()

  for (j in seq_along(categories)) {
    b <- as.numeric(categories[j])
    test_logit_bin <- ifelse(as.numeric(borough.predictors$PRICE.CAT) == b, 1, 0)
    probs_bin <- logit_probs_list[[b]]
  
    roc_logit <- roc(response = test_logit_bin, predictor = probs_bin)
    auc_stic <- auc(roc_logit)
    auc_logit <- c(auc_logit, auc_stic)
  
    lines(roc_logit, col = colors[j], lwd = 2)
}

  legend("bottomright",
       legend = paste0(categories, " (AUC = ", round(auc_logit, 3), ")"),
       col = colors, lwd = 2)
}

```





```{r AUC_Comparison_and_Final_Analysis}

# AUC values from the models, overall
auc_comparison_nyc <- data.frame(
  Model = c("KNN", "CART", "Neural Net", "Multinomial LR"),
  Low = c(0.721, 0.77, 0.744, 0.655),
  Medium = c(0.687, 0.704, 0.548, 0.618),
  High = c(0.802, 0.852, 0.777, 0.754)
)

auc_comparison_nyc




# AUC values from the models, borough-wise
#Brooklyn
auc_comparison_brooklyn <- data.frame(
  Model = c("KNN", "CART", "Neural Net", "Multinomial LR"),
  Low = c(0.788, 0.688, 0.579, 0.606),
  Medium = c(0.783, 0.651, 0.524, 0.642),
  High = c(0.828, 0.735, 0.547, 0.691)
)

#Manhattan
auc_comparison_manhattan <- data.frame(
  Model = c("KNN", "CART", "Neural Net", "Multinomial LR"),
  Low = c(0.86, 0.512, 0.654, 0.526),
  Medium = c(0.906, 0.495, 0.564, 0.706),
  High = c(0.878, 0.507, 0.502, 0.524)
)

#Bronx
auc_comparison_bronx <- data.frame(
  Model = c("KNN", "CART", "Neural Net", "Multinomial LR"),
  Low = c(0.851, 0.757, 0.548, 0.722),
  Medium = c(0.818, 0.679, 0.537, 0.614),
  High = c(0.891, 0.842, 0.508, 0.808)
)

#Queens
auc_comparison_queens <- data.frame(
  Model = c("KNN", "CART", "Neural Net", "Multinomial LR"),
  Low = c(0.84, 0.787, 0.562, 0.558),
  Medium = c(0.823, 0.706, 0.495, 0.546),
  High = c(0.878, 0.831, 0.537, 0.593)
)

#Staten Island
auc_comparison_staten_island <- data.frame(
  Model = c("KNN", "CART", "Neural Net", "Multinomial LR"),
  Low = c(0.888, 0.804, 0.581, 0.626),
  Medium = c(0.858, 0.735, 0.453, 0.553),
  High = c(0.907, 0.874, 0.553, 0.64)
)

auc_comparison_brooklyn
auc_comparison_manhattan
auc_comparison_bronx
auc_comparison_queens
auc_comparison_staten_island

```
Looking at this, overall, we can tell that the CART (classification trees) is the best model to use overall, as their AUC values are the highest, KNN is the second best, so it is also an alternative in case we are unable to use CART. The Neural Net is 3rd, but as what we will mention later, it is not as useful when it comes to the individual boroughs. Finally, for over all the 5 boroughs, the multinomial logistic regression is the least effective among the 4. 



Looking at each individual borough, we can see that Neural Net underperform compared to the other 3 models. This was due to its predictions having it all into the "High" Category, creating large issues. Likewise, when it comes to individual boroughs, we can see that K- Nearest Neighbors is more effective than the other 3 models, with Classification Trees being in second. 


So, when it comes to the individual boroughs, classifying based on sale price would be more effective using K-Nearest Neighbors, while for the overall data of New York City, we would instead use Classification Trees.









