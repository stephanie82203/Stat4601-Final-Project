---
title: "Stat4601_Final_Unsupervised_learning"
author: "Stephanie Cheng"
date: "2025-04-09"
output: pdf_document
---

```{r setup, include=FALSE}
library(here)
library(ggplot2)
library(RColorBrewer)
library(stats)
library(dplyr)
library(tidyr)
library(mda) 

load("manhattan_data.RData")
load("bronx_data.RData")
load("brooklyn_data.RData")
load("queens_data.RData")
load("staten_island_data.RData")
load("new_york_city_data.RData")

source("vq_helpers.r")
```


```{r test}
# remove the rows that has NA value 
manhattan_pca <- na.omit(manhattan_data)
bronx_pca <- na.omit(bronx_data)
brooklyn_pca <- na.omit(brooklyn_data)
queens_pca <- na.omit(queens_data)
staten_island_pca <- na.omit(staten_island_data)

manhattan_filtered_data <- na.omit(manhattan_data)
```

```{r PCA}
# Drop the columns with zero variance (constant value)
manhattan_pca <- manhattan_pca %>%
 select(where(~ var(.x) != 0))
bronx_pca <- bronx_pca %>%
  select(where(~ var(.x) != 0))
brooklyn_pca <- brooklyn_pca %>%
  select(where(~ var(.x) != 0))
queens_pca <- queens_pca %>%
  select(where(~ var(.x) != 0))
staten_island_pca <- staten_island_pca %>%
  select(where(~ var(.x) != 0))


# Apply PCA for each dataset
manhattan_pca <- prcomp(manhattan_pca, scale.=TRUE)
bronx_pca <- prcomp(bronx_pca, scale.=TRUE)
brooklyn_pca <- prcomp(brooklyn_pca, scale.=TRUE)
queens_pca <- prcomp(queens_pca, scale.=TRUE)
staten_island_pca <- prcomp(staten_island_pca, scale.=TRUE)


# Print out the summary for each PCA
summary(manhattan_pca)
summary(bronx_pca)
summary(brooklyn_pca)
summary(queens_pca)
summary(staten_island_pca)

# Show the name of PCs
apply(manhattan_pca$rotation, 2, function(x) {
  names(x)[which.max(abs(x))]
})
```

```{r k-mean}
# Pick the best k using Davies-Bouldin index
X.syn <- manhattan_pca$x[, 1:13]

oldpar <- par(mfrow = c(4, 4)) 
par(mar = c(2, 2, 2, 1))        
errs <- rep(0, 13)             
DBI <- rep(0, 13)
colors <- rainbow(14)

for (i in 2:14) {
   set.seed(1234)
   KM <- kmeans(X.syn, i, 15)
   plot(X.syn[, 1:2], col = colors[KM$cluster], pch = KM$cluster,
        main = paste(i, "clusters"), xlab = "PC1", ylab = "PC2")
   errs[i - 1] <- sum(KM$withinss)
   DBI[i - 1] <- Davies.Bouldin(KM$centers, KM$withinss, KM$size)
}
# reset plotting setting
par(oldpar)

best_k <- which.min(DBI) + 1
cat("Best k by DBI:", best_k, "\n")

# plot Sum of Squares Line Chart and 
plot(2:14, errs, main = "SS")
lines(2:14, errs, lwd = 2, pch = 20, cex = 1.5)
# plot Davies-Bouldin Index Line Chart
plot(2:14, DBI, main = "Davies-Bouldin")
lines(2:14, DBI, lwd = 2, pch = 20, cex = 1.5)
```

```{r k-mean2}
KM_final <- kmeans(X.syn, centers = best_k, nstart = 25)
plot(X.syn[, 1:2], col = KM_final$cluster, pch = KM_final$cluster,
     main = paste("Final Clustering with k =", best_k),
     xlab = "PC1", ylab = "PC2")
points(KM_final$centers[, 1:2], pch = 4, col = 1:best_k, cex = 2, lwd = 2)

# Interpret the Clusters
cluster_labels <- KM_final$cluster
manhattan_filtered_data$cluster <- cluster_labels 

# Summarize key features by cluster
aggregate(manhattan_filtered_data, by = list(cluster = cluster_labels), FUN = mean, na.rm = TRUE)
```

```{r test2}
str(new_york_city_pca)
```

```{r hierarchical}
new_york_city_pca <- na.omit(new_york_city_data)
new_york_city_pca <- new_york_city_pca %>%
  select(where(~ var(.x) != 0))
new_york_city_pca <- prcomp(new_york_city_pca, scale.=TRUE)
X.syn <- new_york_city_pca$x[, 1:13]
dist_matrix <- dist(X.syn, method = "euclidean")
hc <- hclust(dist_matrix, method = "ward.D2")
plot(hc, labels = FALSE, main = "Hierarchical Clustering Dendrogram")
rect.hclust(hc, k = best_k, border = "steelblue")
clusters <- cutree(hc, k = best_k)  
table(clusters)
```